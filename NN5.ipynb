{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP06v4ginvQd8pzlRwkpR1/"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BT1_Qz9DC6sg"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, regularizers\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "def load_data():\n",
        "    (x_train, y_train), (x_test, y_test) = keras.datasets.fashion_mnist.load_data()\n",
        "    x_train, x_test = x_train / 255.0, x_test / 255.0  # Normalize\n",
        "    x_train = x_train.reshape(-1, 28, 28, 1)\n",
        "    x_test = x_test.reshape(-1, 28, 28, 1)\n",
        "    return (x_train, y_train), (x_test, y_test)\n",
        "\n",
        "def create_model(filter_size=32, kernel_size=(3,3), reg=None, optimizer='adam'):\n",
        "    model = keras.Sequential([\n",
        "        layers.Conv2D(filter_size, kernel_size, activation='relu', input_shape=(28,28,1), kernel_regularizer=reg),\n",
        "        layers.MaxPooling2D((2,2)),\n",
        "        layers.Conv2D(filter_size * 2, kernel_size, activation='relu', kernel_regularizer=reg),\n",
        "        layers.MaxPooling2D((2,2)),\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(128, activation='relu', kernel_regularizer=reg),\n",
        "        layers.Dense(10, activation='softmax')\n",
        "    ])\n",
        "    model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "def train_and_evaluate(filter_size=32, kernel_size=(3,3), reg=None, batch_size=32, optimizer='adam', epochs=20):\n",
        "    (x_train, y_train), (x_test, y_test) = load_data()\n",
        "    model = create_model(filter_size, kernel_size, reg, optimizer)\n",
        "    history = model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_data=(x_test, y_test))\n",
        "    return model, history, (x_test, y_test)\n",
        "\n",
        "def plot_performance(history):\n",
        "    plt.figure(figsize=(12, 4))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
        "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(history.history['loss'], label='Train Loss')\n",
        "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "def plot_confusion_matrix(model, x_test, y_test):\n",
        "    y_pred = np.argmax(model.predict(x_test), axis=1)\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=range(10), yticklabels=range(10))\n",
        "    plt.xlabel('Predicted Label')\n",
        "    plt.ylabel('True Label')\n",
        "    plt.title('Confusion Matrix')\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "model1, history1, (x_test1, y_test1) = train_and_evaluate(filter_size=32, kernel_size=(3,3), reg=None, batch_size=32, optimizer='adam', epochs=20)\n",
        "plot_performance(history1)\n",
        "plot_confusion_matrix(model1, x_test1, y_test1)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
        "26421880/26421880 [==============================] - 8s 0us/step\n",
        "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
        "5148/5148 [==============================] - 0s 0s/step\n",
        "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
        "4422102/4422102 [==============================] - 1s 0us/step\n",
        "Epoch 1/20\n",
        "1875/1875 [==============================] - 324s 170ms/step - loss: 0.4508 - accuracy: 0.8351 - val_loss: 0.3622 - val_accuracy: 0.8716\n",
        "Epoch 2/20\n",
        "1875/1875 [==============================] - 298s 159ms/step - loss: 0.3022 - accuracy: 0.8896 - val_loss: 0.2947 - val_accuracy: 0.8953\n",
        "Epoch 3/20\n",
        "1875/1875 [==============================] - 295s 157ms/step - loss: 0.2594 - accuracy: 0.9035 - val_loss: 0.2782 - val_accuracy: 0.8979\n",
        "Epoch 4/20\n",
        "1875/1875 [==============================] - 287s 153ms/step - loss: 0.2267 - accuracy: 0.9154 - val_loss: 0.2683 - val_accuracy: 0.9015\n",
        "Epoch 5/20\n",
        "1875/1875 [==============================] - 270s 144ms/step - loss: 0.1997 - accuracy: 0.9251 - val_loss: 0.2608 - val_accuracy: 0.9056\n",
        "Epoch 6/20\n",
        "1875/1875 [==============================] - 278s 148ms/step - loss: 0.1771 - accuracy: 0.9337 - val_loss: 0.2499 - val_accuracy: 0.9065\n",
        "Epoch 7/20\n",
        "1875/1875 [==============================] - 276s 147ms/step - loss: 0.1545 - accuracy: 0.9420 - val_loss: 0.2790 - val_accuracy: 0.9029\n",
        "Epoch 8/20\n",
        "1875/1875 [==============================] - 286s 152ms/step - loss: 0.1368 - accuracy: 0.9481 - val_loss: 0.2659 - val_accuracy: 0.9085\n",
        "Epoch 9/20\n",
        "1875/1875 [==============================] - 239s 127ms/step - loss: 0.1202 - accuracy: 0.9545 - val_loss: 0.2734 - val_accuracy: 0.9125\n",
        "Epoch 10/20\n",
        "1875/1875 [==============================] - 234s 125ms/step - loss: 0.1067 - accuracy: 0.9602 - val_loss: 0.3254 - val_accuracy: 0.9072\n",
        "Epoch 11/20\n",
        "1875/1875 [==============================] - 234s 125ms/step - loss: 0.0930 - accuracy: 0.9646 - val_loss: 0.3231 - val_accuracy: 0.9092\n",
        "Epoch 12/20\n",
        "1875/1875 [==============================] - 236s 126ms/step - loss: 0.0830 - accuracy: 0.9687 - val_loss: 0.3350 - val_accuracy: 0.9045\n",
        "Epoch 13/20\n",
        "1875/1875 [==============================] - 238s 127ms/step - loss: 0.0747 - accuracy: 0.9714 - val_loss: 0.3272 - val_accuracy: 0.9107\n",
        "Epoch 14/20\n",
        "1875/1875 [==============================] - 7799s 4s/step - loss: 0.0662 - accuracy: 0.9749 - val_loss: 0.3823 - val_accuracy: 0.8966\n",
        "Epoch 15/20\n",
        "1875/1875 [==============================] - 269s 143ms/step - loss: 0.0584 - accuracy: 0.9778 - val_loss: 0.3914 - val_accuracy: 0.9098\n",
        "Epoch 16/20\n",
        "1875/1875 [==============================] - 274s 146ms/step - loss: 0.0513 - accuracy: 0.9804 - val_loss: 0.4417 - val_accuracy: 0.9046\n",
        "Epoch 17/20\n",
        "1875/1875 [==============================] - 276s 147ms/step - loss: 0.0477 - accuracy: 0.9817 - val_loss: 0.4454 - val_accuracy: 0.9028\n",
        "Epoch 18/20\n",
        "1875/1875 [==============================] - 275s 147ms/step - loss: 0.0442 - accuracy: 0.9835 - val_loss: 0.4556 - val_accuracy: 0.9037\n",
        "Epoch 19/20\n",
        "1875/1875 [==============================] - 263s 140ms/step - loss: 0.0417 - accuracy: 0.9846 - val_loss: 0.4862 - val_accuracy: 0.9018\n",
        "Epoch 20/20\n",
        "1875/1875 [==============================] - 247s 132ms/step - loss: 0.0374 - accuracy: 0.9866 - val_loss: 0.4843 - val_accuracy: 0.9061\n",
        "\n",
        "313/313 [==============================] - 14s 43ms/step\n"
      ],
      "metadata": {
        "id": "eRCJ33A5FwT_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}