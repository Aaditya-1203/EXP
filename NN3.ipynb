{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNe98R8MYEGwF2nxYc6XntF"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "88GxWW2VCrf2",
        "outputId": "3148d6b5-6ba7-45ed-8058-9a17c46f16b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Epoch 1, Loss: 0.1293, Train Accuracy: 96.01, Test Accuracy: 95.63\n",
            "Epoch 2, Loss: 0.0933, Train Accuracy: 97.09, Test Accuracy: 96.47\n",
            "Epoch 3, Loss: 0.0838, Train Accuracy: 97.35, Test Accuracy: 96.33\n",
            "Epoch 4, Loss: 0.0832, Train Accuracy: 97.23, Test Accuracy: 95.89\n",
            "Epoch 5, Loss: 0.0729, Train Accuracy: 97.56, Test Accuracy: 96.36\n",
            "Epoch 6, Loss: 0.0694, Train Accuracy: 97.68, Test Accuracy: 96.54\n",
            "Epoch 7, Loss: 0.0509, Train Accuracy: 98.35, Test Accuracy: 96.94\n",
            "Epoch 8, Loss: 0.0407, Train Accuracy: 98.60, Test Accuracy: 97.07\n",
            "Epoch 9, Loss: 0.0509, Train Accuracy: 98.32, Test Accuracy: 96.92\n",
            "Epoch 10, Loss: 0.0358, Train Accuracy: 98.83, Test Accuracy: 97.14\n",
            "Epoch 11, Loss: 0.0428, Train Accuracy: 98.58, Test Accuracy: 97.09\n",
            "Epoch 12, Loss: 0.0458, Train Accuracy: 98.51, Test Accuracy: 96.92\n",
            "Epoch 13, Loss: 0.0366, Train Accuracy: 98.81, Test Accuracy: 96.93\n",
            "Epoch 14, Loss: 0.0263, Train Accuracy: 99.12, Test Accuracy: 97.03\n",
            "Epoch 15, Loss: 0.0269, Train Accuracy: 99.10, Test Accuracy: 97.12\n",
            "Epoch 16, Loss: 0.0229, Train Accuracy: 99.22, Test Accuracy: 97.32\n",
            "Epoch 17, Loss: 0.0367, Train Accuracy: 98.76, Test Accuracy: 96.93\n",
            "Epoch 18, Loss: 0.0234, Train Accuracy: 99.20, Test Accuracy: 97.36\n",
            "Epoch 19, Loss: 0.0225, Train Accuracy: 99.26, Test Accuracy: 97.37\n",
            "Epoch 20, Loss: 0.0201, Train Accuracy: 99.32, Test Accuracy: 97.58\n",
            "Final Train Accuracy: 99.32\n",
            "Final Test Accuracy: 97.58\n",
            "Training Complete!\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow.python.framework.ops import disable_eager_execution\n",
        "\n",
        "disable_eager_execution()  # Disable eager execution to use TensorFlow's graph execution\n",
        "\n",
        "# Load MNIST dataset\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "x_train, x_test = x_train.reshape(-1, 784) / 255.0, x_test.reshape(-1, 784) / 255.0\n",
        "\n",
        "# Convert labels to one-hot encoding\n",
        "y_train = np.eye(10)[y_train]\n",
        "y_test = np.eye(10)[y_test]\n",
        "\n",
        "# Define model hyperparameters\n",
        "input_size = 784\n",
        "hidden1_size = 128\n",
        "hidden2_size = 64\n",
        "output_size = 10\n",
        "learning_rate = 0.01\n",
        "batch_size = 100\n",
        "epochs = 20\n",
        "\n",
        "# Define placeholders for input and output\n",
        "X = tf.compat.v1.placeholder(tf.float32, [None, input_size])\n",
        "y = tf.compat.v1.placeholder(tf.float32, [None, output_size])\n",
        "\n",
        "# Initialize weights and biases\n",
        "weights = {\n",
        "    'w1': tf.Variable(tf.random.truncated_normal([input_size, hidden1_size], stddev=0.1)),\n",
        "    'w2': tf.Variable(tf.random.truncated_normal([hidden1_size, hidden2_size], stddev=0.1)),\n",
        "    'w3': tf.Variable(tf.random.truncated_normal([hidden2_size, output_size], stddev=0.1))\n",
        "}\n",
        "\n",
        "biases = {\n",
        "    'b1': tf.Variable(tf.zeros([hidden1_size])),\n",
        "    'b2': tf.Variable(tf.zeros([hidden2_size])),\n",
        "    'b3': tf.Variable(tf.zeros([output_size]))\n",
        "}\n",
        "\n",
        "# Define feed-forward neural network\n",
        "def neural_network(X):\n",
        "    layer1 = tf.nn.sigmoid(tf.matmul(X, weights['w1']) + biases['b1'])\n",
        "    layer2 = tf.nn.sigmoid(tf.matmul(layer1, weights['w2']) + biases['b2'])\n",
        "    output_layer = tf.matmul(layer2, weights['w3']) + biases['b3']\n",
        "    return output_layer\n",
        "\n",
        "# Compute logits\n",
        "logits = neural_network(X)\n",
        "\n",
        "# Define loss function (cross-entropy)\n",
        "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y, logits=logits))\n",
        "\n",
        "# Define optimizer\n",
        "optimizer = tf.compat.v1.train.AdamOptimizer(learning_rate=learning_rate).minimize(loss)\n",
        "\n",
        "# Define accuracy metric\n",
        "correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(y, 1))\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
        "\n",
        "# Run session\n",
        "tf.compat.v1.disable_eager_execution()\n",
        "with tf.compat.v1.Session() as sess:\n",
        "    sess.run(tf.compat.v1.global_variables_initializer())\n",
        "\n",
        "    # Training loop\n",
        "    for epoch in range(epochs):\n",
        "        for i in range(0, len(x_train), batch_size):\n",
        "            batch_x, batch_y = x_train[i:i+batch_size], y_train[i:i+batch_size]\n",
        "            sess.run(optimizer, feed_dict={X: batch_x, y: batch_y})\n",
        "\n",
        "        # Calculate and display loss and accuracy at each epoch\n",
        "        train_loss, train_acc = sess.run([loss, accuracy], feed_dict={X: x_train, y: y_train})\n",
        "        test_acc = sess.run(accuracy, feed_dict={X: x_test, y: y_test})\n",
        "        print(f\"Epoch {epoch+1}, Loss: {train_loss:.4f}, Train Accuracy: {train_acc*100:.2f}, Test Accuracy: {test_acc*100:.2f}\")\n",
        "\n",
        "    # Compute final train and test accuracy\n",
        "    final_train_acc = sess.run(accuracy, feed_dict={X: x_train, y: y_train})\n",
        "    final_test_acc = sess.run(accuracy, feed_dict={X: x_test, y: y_test})\n",
        "    print(f\"Final Train Accuracy: {final_train_acc*100:.2f}\")\n",
        "    print(f\"Final Test Accuracy: {final_test_acc*100:.2f}\")\n",
        "\n",
        "    print(\"Training Complete!\")"
      ]
    }
  ]
}